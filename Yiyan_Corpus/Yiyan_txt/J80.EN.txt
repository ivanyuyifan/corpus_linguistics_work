1 Introduction 
In which we try to explain why we consider artificial intelligence to be a subject most worthy of study, and in which we try to decide what exactly it is, this being a good thing to decide before embarking.
We call ourselves Homo sapiens--man the wise--because our intelligence is so important to us. 
For thousands of years, we have tried to understand how we think; that is, how a mere handful of matter can perceive, understand, predict, and manipulate a world far larger and more complicated than itself. 
The field of artificial intelligence, or AI, goes further still: it attempts not just to understand but also to build intelligent entities.
AI is one of the newest fields in science and engineering. 
Work started in earnest soon after World War II, and the name itself was coined in 1956. 
Along with molecular biology, AI is regularly cited as the ¡°field I would most like to be in¡± by scientists in other disciplines. 
A student in physics might reasonably feel that all the good ideas have already been taken by Galileo, Newton, Einstein, and the rest. 
AI, on the other hand, still has openings for several full-time Einsteins and Edisons.
AI currently encompasses a huge variety of subfields, ranging from the general (learning and perception) to the specific, such as playing chess, proving mathematical theorems, writing poetry, driving a car on a crowded street, and diagnosing diseases. 
AI is relevant to any intellectual task; it is truly a universal field.
1.1 What Is AI?
We have claimed that AI is exciting, but we have not said what it is. 
In Figure 1.1 we see eight definitions of AI, laid out along two dimensions. 
The definitions on top are concerned with thought processes and reasoning, whereas the ones on the bottom address behavior. 
The definitions on the left measure success in terms of fidelity to human performance, whereas rationality the ones on the right measure against an ideal performance measure, called rationality. 
A system is rational if it does the ¡°right thing¡± given what it knows.
Historically, all four approaches to AI have been followed, each by different people with different methods. 
A human-centered approach must be in part an empirical science, involving observations and hypotheses about human behavior. 
A rationalist approach involves a combination of mathematics and engineering. 
The various group have both disparaged and helped each other. 
Let us look at the four approaches in more detail.
Thinking Humanly
¡°The exciting new effort to make computers think ... machines with minds, in the full and literal sense.¡± (Haugeland, 1985)
¡°[The automation of] activities that we associate with human thinking, activities such as decision-making, problem solving, learning ...¡±(Bellman, 1978)
Thinking Rationally 
¡°The study of mental faculties through the use of computational models.¡± (Chamiak and McDermott, 1985) 
¡°The study of the computations that make it possible to perceive, reason, and act.¡± (Winston, 1992)
Acting Humanly 
¡°The art of creating machines that perform functions that require intelligence when performed by people.¡± (Kurzweil, 1990) 
¡°The study of how to make computers do things at which, at the moment, people are better.¡± (Rich and Knight, 1991)
Acting Rationally 
¡°Computational Intelligence is the study of the design of intelligent agents.¡± (Poole et al., 1998) 
¡°AI ... is concerned with intelligent behavior in artifacts.¡± (Nilsson, 1998) 
Figure 1.1 Some definitions of artificial intelligence, organized into four categories.
Acting humanly: The Turing Test approach 
The Turing Test, proposed by Alan Turing (1950), was designed to provide a satisfactory operational definition of intelligence. 
A computer passes the test if a human interrogator, after posing some written questions, cannot tell whether the written responses come from a person or from a computer. 
Chapter 26 discusses the details of the test and whether a computer would really be intelligent if it passed. 
For now, we note that programming a computer to pass a rigorously applied test provides plenty to work on. 
The computer would need to possess the following capabilities:
natural language processing to enable it to communicate successfully in English;
knowledge representation to store what it knows or hears;
automated reasoning to use the stored information to answer questions and to draw new conclusions; 
machine learning to adapt to new circumstances and to detect and extrapolate patterns.
Turing¡¯s test deliberately avoided direct physical interaction between the interrogator and the computer, because physical simulation of a person is unnecessary for intelligence. 
However, the so-called total Turing Test includes a video signal so that the interrogator can test the subject¡¯s perceptual abilities, as well as the opportunity for the interrogator to pass physical objects ¡°through the hatch.¡± 
To pass the total Turing Test, the computer will needComputer vision to perceive objects, and robotics to manipulate objects and move about.
These six disciplines compose most of AI, and Turing deserves credit for designing a test that remains relevant 60 years later. 
Yet AI researchers have devoted little effort to passing the Turing Test, believing that it is more important to study the underlying principles of intelligence than to duplicate an exemplar. 
The quest for ¡°artificial flight¡± succeeded when the Wright brothers and others stopped imitating birds and started using wind tunnels and learning about aerodynamics. 
Aeronautical engineering texts do not define the goal of their field as making ¡°machines that fly so exactly like pigeons that they can fool even other pigeons.¡±
Thinking humanly: The cognitive modeling approach 
If we are going to say that a given program thinks like a human, we must have some way of determining how humans think. 
We need to get inside the actual workings of human minds. 
There are three ways to do this: through introspection¡ªtrying to catch our own thoughts as they go by; through psychological experiments¡ªobserving a person in action; and through brain imaging¡ªobserving the brain in action. 
Once we have a sufficiently precise theory of the mind, it becomes possible to express the theory as a computer program. 
If the program¡¯s input-output behavior matches corresponding human behavior, that is evidence that some of the program¡¯s mechanisms could also be operating in humans. 
For example, Allen Newell and Herbert Simon, who developed GPS, the ¡°General Problem Solver¡± (Newell and Simon, 1961), were not content merely to have their program solve problems correctly. 
They were more concerned with comparing the trace of its reasoning steps to traces of human subjects cognitive science solving the same problems. 
The interdisciplinary field of cognitive science brings together computer models from AI and experimental techniques from psychology to construct precise and testable theories of the human mind.
Cognitive science is a fascinating field in itself, worthy of several textbooks and at least one encyclopedia (Wilson and Keil, 1999). 
We will occasionally comment on similarities or differences between AI techniques and human cognition. 
Real cognitive science, however, is necessarily based on experimental investigation of actual humans or animals. 
We will leave that for other books, as we assume the reader has only a computer for experimentation.
In the early days of AI there was often confusion between the approaches: an author would argue that an algorithm performs well on a task and that it is therefore a good model of human performance, or vice versa. 
Modern authors separate the two kinds of claims; this distinction has allowed both AI and cognitive science to develop more rapidly. 
The two fields continue to fertilize each other, most notably in computer vision, which incorporates neurophysiological evidence into computational models.
Thinking rationally: The ¡°laws of thought¡± approach 
The Greek philosopher Aristotle was one of the first to attempt to codify ¡°right thinking,¡± that is, irrefutable reasoning processes. 
His syllogisms provided patterns for argument structures that always yielded correct conclusions when given correct premises--for example, ¡°Socrates is a man; all men are mortal; therefore, Socrates is mortal.¡± 
These laws of thought were supposed to govern the operation of the mind; their study initiated the field called logic.
Logicians in the 19th century developed a precise notation for statements about all kinds of objects in the world and the relations among them. (Contrast this with ordinary arithmetic notation, which provides only for statements about numbers.)
 By 1965, programs existed that could, in principle, solve any solvable problem described in logical notation. (Although if no solution exists, the program might loop forever.) 
The so-called logicist tradition within artificial intelligence hopes to build on such programs to create intelligent systems.
There are two main obstacles to this approach. 
First, it is not easy to take informal knowledge and state it in the formal terms required by logical notation, particularly when the knowledge is less than 100% certain. 
Second, there is a big difference between solving a problem ¡°in principle¡± and solving it in practice. 
Even problems with just a few hundred facts can exhaust the computational resources of any computer unless it has some guidance as to which reasoning steps to try first. 
Although both of these obstacles apply to any attempt to build computational reasoning systems, they appeared first in the logicist tradition.
Acting rationally: The rational agent approach 
An agent is just something that acts (agent comes from the Latin agere, to do). 
Of course, all computer programs do something, but computer agents are expected to do more: operate autonomously, perceive their environment, persist over a prolonged time period, adapt to rational agent change, and create and pursue goals. 
A rational agent is one that acts so as to achieve the best outcome or, when there is uncertainty, the best expected outcome.
In the ¡°laws of thought¡± approach to AI, the emphasis was on correct inferences. 
Making correct inferences is sometimes part of being a rational agent, because one way to act rationally is to reason logically to the conclusion that a given action will achieve one¡¯s goals and then to act on that conclusion. 
On the other hand, correct inference is not all of rationality; in some situations, there is no provably correct thing to do, but something must still be done. 
There are also ways of acting rationally that cannot be said to involve inference. 
For example, recoiling from a hot stove is a reflex action that is usually more successful than a slower action taken after careful deliberation.
All the skills needed for the Turing Test also allow an agent to act rationally. 
Knowledge representation and reasoning enable agents to reach good decisions. 
We need to be able to generate comprehensible sentences in natural language to get by in a complex society. 
We need learning not only for erudition, but also because it improves our ability to generate effective behavior.
The rational-agent approach has two advantages over the other approaches. 
First, it is more general than the ¡°laws of thought¡± approach because correct inference is just one of several possible mechanisms for achieving rationality. 
Second, it is more amenable to scientific development than are approaches based on human behavior or human thought. 
The standard of rationality is mathematically well defined and completely general, and can be ¡°unpacked¡± to generate agent designs that provably achieve it. 
Human behavior, on the other hand, is well adapted for one specific environment and is defined by, well, the sum total of all the things that humans do. 
This book therefore concentrates on general principles of rational agents and on components for constructing them. 
We will see that despite the apparent simplicity with which the problem can be stated, an enormous variety of issues come up when we try to solve it. 
Chapter 2 outlines some of these issues in more detail.
One important point to keep in mind: We will see before too long that achieving perfect rationality¡ªalways doing the right thing¡ªis not feasible in complicated environments. 
The computational demands are just too high. 
For most of the book, however, we will adopt the working hypothesis that perfect rationality is a good starting point for analysis. 
It simplifies the problem and provides the appropriate setting for most of the foundational material in the field. 
Chapters 5 and 17 deal explicitly with the issue of limited rationality¡ªacting appropriately when there is not enough time to do all the computations one might like.